<p>There has been a surge in crimes committed in recent years, making crime a top cause of concern for law enforcement. If we are able to estimate whether someone is going to commit a crime in the future, we can take precautions and be prepared.</p>

<p>You are given a dataset containing answers to various questions concerning the professional and private lives of several people. A few of them have been arrested for various small and large crimes in the past. Use the given data to predict if the people in the test data will commit a crime. The train data consists of 45718 rows, while the test data consists of 11430 rows.</p>

<p>The evaluation metric is precision score.</p>

<h3 id="download-dataset"><a href="https://he-s3.s3.amazonaws.com/media/hackathon/predict-the-criminal/predict-the-criminal/d17428d0-e-Criminal.rar">Download Dataset</a></h3>

<p>Here is how this problem can be solved using SVM</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>%matplotlib inline
import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_csv('./e_criminal/criminal_train.csv')
df.head()
</code></pre></div></div>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td>PERID</td>
      <td>IFATHER</td>
      <td>NRCH17_2</td>
      <td>IRHHSIZ2</td>
      <td>IIHHSIZ2</td>
      <td>IRKI17_2</td>
      <td>IIKI17_2</td>
      <td>IRHH65_2</td>
      <td>IIHH65_2</td>
      <td>PRXRETRY</td>
      <td>…</td>
      <td>TOOLONG</td>
      <td>TROUBUND</td>
      <td>PDEN10</td>
      <td>COUTYP2</td>
      <td>MAIIN102</td>
      <td>AIIND102</td>
      <td>ANALWT_C</td>
      <td>VESTR</td>
      <td>VEREP</td>
      <td>Criminal</td>
    </tr>
    <tr>
      <td>0</td>
      <td>25095143</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>99</td>
      <td>…</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>3884.805998</td>
      <td>40026</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>13005143</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>99</td>
      <td>…</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>1627.108106</td>
      <td>40015</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2</td>
      <td>67415143</td>
      <td>4</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>99</td>
      <td>…</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>4344.957980</td>
      <td>40024</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>70925143</td>
      <td>4</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>99</td>
      <td>…</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>792.521931</td>
      <td>40027</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>75235143</td>
      <td>1</td>
      <td>0</td>
      <td>6</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>99</td>
      <td>…</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>1518.118526</td>
      <td>40001</td>
      <td>2</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>5 rows × 72 columns</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import numpy as np
X = df.iloc[: ,:-1]
Y = df.iloc[: , X.shape[1]:]
Y = np.ravel(Y)
Y.shape


(45718,)

# Feature Selection

# Recursive Feature Elimination (RFE) is based on the idea to repeatedly
# construct a model and choose either the best or worst performing feature,
# setting the feature aside and then repeating the process with the rest of the features

from sklearn import datasets
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression()

rfe = RFE(logreg, 18)
rfe = rfe.fit(X, Y)
print(rfe.support_)
print(rfe.ranking_)


[False  True False  True False  True False False False False False False
 False False False False  True False False False False False False False
 False False False False  True False  True False  True False False False
 False False False False False  True False False  True False False False
  True False  True False  True False False  True  True  True False False
  True  True False False False False False  True False False False]
[28  1 35  1 38  1 37 51 36 21 13 53 18 54  2  3  1 11 20 15  5 24 23 25 16
 17 33 48  1 44  1 41  1 50  6  4  9 12 14 34 49  1 32 52  1 40 19 47  1 39
  1 46  1 45 22  1  1  1 43 42  1  1  8  7 31 30 10  1 27 26 29]


# Normalize the data
from sklearn import preprocessing
x = df.values #returns a numpy array

min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
X = pd.DataFrame(x_scaled)


X = X[[column for consider, column in zip(rfe.support_, X.columns) if consider]]

from sklearn.cross_validation import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)


import pandas as pd
import numpy as np
from sklearn import svm, datasets
import matplotlib.pyplot as plt

C = 1.0 # SVM regularization parameter
svc = svm.SVC(kernel='linear', C=C, decision_function_shape='ovr').fit(X_train, y_train)
y_pred = svc.predict(X_test)


from sklearn.metrics import confusion_matrix, f1_score
confusion = confusion_matrix(y_test, y_pred)
#print(confusion)
tn, fp, fn, tp = confusion.ravel()
# TrueNegative, FalsePositive, Falsenegative, TruePositive

print "========== Criminal prediction output ============"
print "Correct predictions = ", tn+tp


print "INCorrect predictions = ", fp+fn

score = f1_score(y_test, y_pred)
print score


========== Criminal prediction output ============
Correct predictions =  12724
INCorrect predictions =  992
0.0
</code></pre></div></div>
